# Data preparation
initialize doc_term_freq, term_term_freq, term_term_ratio

for doc_index in corpus
    for token in tokenize (d)
        #add doc_word_matrix
        doc_term_freq[doc_index][token] += 1

        # add the doc that word belong
        word_docs[token].append(doc_index)

    for token1 in word_docs:
        for token2 in word_docs:
            term_term_freq[token1][token2] = len(set(wd1).intersection(set(wd2)))
			term_term_ratio[token1][token2] = term_term_freq[token1][token2] / len(wd1) if len(wd1) > 0 else 0

