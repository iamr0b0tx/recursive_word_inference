-------------------------------------------------- Preprocessing! -------------------------------------------------- 

-------------------------------------------------- Building Document Term Matrix! --------------------------------------------------

-------------------------------------------------- Building Word Occurrence and Co-occurrence! --------------------------------------------------

    0    1    2    3    4    5    6   ...   93   94   95   96   97   98   99
0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
1  0.0  1.0  0.0  1.0  0.0  1.0  1.0  ...  0.0  0.0  1.0  1.0  0.0  0.0  0.0
2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  1.0  0.0
4  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  1.0  0.0  0.0
5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0
6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0

[7 rows x 100 columns] 

============================================================ Training! ============================================================ 


 -------------------------------------------------- Constructing Topic word distribution! --------------------------------------------------


 -------------------------------------------------- Checking for informative words! --------------------------------------------------
   a.m.  a0-size  aamir  abandon  ...  zeh  zirconium  zone  zoomed
0   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
1   0.0      1.0    0.0      1.0  ...  1.0        0.0   0.0     0.0
2   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
3   0.0      0.0    1.0      0.0  ...  0.0        0.0   0.0     1.0
4   0.0      0.0    0.0      0.0  ...  0.0        1.0   0.0     0.0
5   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
6   1.0      0.0    0.0      0.0  ...  0.0        0.0   1.0     0.0

[7 rows x 5187 columns]


 -------------------------------------------------- Trimming for informative words! --------------------------------------------------


 -------------------------------------------------- Infering best_word-word ratio! --------------------------------------------------

 -------------------------------------------------- Infering word-word ratio! --------------------------------------------------
                         ========================= Topic (word) distribution! =========================                         
   a.m.  a0-size  aamir  abandon  ...  zeh  zirconium  zone  zoomed
0   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
1   0.0      1.0    0.0      1.0  ...  1.0        0.0   0.0     0.0
2   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
3   0.0      0.0    1.0      0.0  ...  0.0        0.0   0.0     1.0
4   0.0      0.0    0.0      0.0  ...  0.0        1.0   0.0     0.0
5   0.0      0.0    0.0      0.0  ...  0.0        0.0   0.0     0.0
6   1.0      0.0    0.0      0.0  ...  0.0        0.0   1.0     0.0

[7 rows x 5187 columns]

Topic 0
==========
excluding     1.0
conspiracy    1.0
explicit      1.0
doubtful      1.0
logic         1.0
consistent    1.0
fullfilled    1.0
agrees        1.0
guitar        1.0
ohio          1.0
Name: 0, dtype: float64

Topic 1
==========
q30tbxn+b^wm          1.0
mbxn+bxn+bxn+bxn+-    1.0
clarkec               1.0
clarke                1.0
mas                   1.0
font                  1.0
seq                   1.0
marketing             1.0
citing                1.0
servis                1.0
Name: 1, dtype: float64

Topic 2
==========
analyzer      1.0
hotel         1.0
airports      1.0
condition     1.0
netters       1.0
pink          1.0
conponents    1.0
todd          1.0
las           1.0
hmmm          1.0
Name: 2, dtype: float64

Topic 3
==========
zoomed      1.0
lojack      1.0
alot        1.0
locks       1.0
wfan        1.0
wetting     1.0
fashion     1.0
guzman      1.0
haggling    1.0
iskander    1.0
Name: 3, dtype: float64

Topic 4
==========
ciphertext    1.0
cylinders     1.0
pushing       1.0
pusher        1.0
lab           1.0
l.a.          1.0
purtill       1.0
purposes      1.0
daily         1.0
gaas          1.0
Name: 4, dtype: float64

Topic 5
==========
grace         1.0
fedex         1.0
graciously    1.0
modern-day    1.0
sickness      1.0
std           1.0
burnet        1.0
developed     1.0
skin          1.0
pennance      1.0
Name: 5, dtype: float64

Topic 6
==========
logjam       1.0
laid         1.0
laughable    1.0
latin        1.0
latent       1.0
lately       1.0
larger       1.0
landed       1.0
land         1.0
ktvb         1.0
Name: 6, dtype: float64

100 doc(s) read and 5187 word(s) in the vocabulary
Topics found via LDA:
===========================
Topic #0: proceedings des cryptography encryption key computer pub security ieee cryptology
Topic #1: ax max pl 1d9 b8f wm 3t g9v 0t bxn
Topic #2: xxxx ve don line sure speed just work windows high
Topic #3: people like think ve country know look president things time
Topic #4: war south secret rockefeller nuclear new military island georgia naval
Topic #5: sex don display point nsa people want aids government mitre
Topic #6: weaver people want don power harris fadeley god use real

Classification
=====================================
doc 0: topic = [talk  = 0.0163, sci   = 0.0086, comp  = 0.0083, lda = 6], class = rec: rec.sport.hockey
doc 1: topic = [talk  = 0.0211, sci   = 0.0104, comp  = 0.0092, lda = 6], class = talk: talk.politics.guns
doc 2: topic = [sci   = 0.0115, talk  = 0.0072, alt   = 0.0041, lda = 6], class = sci: sci.space
doc 3: topic = [talk  = 0.0108, sci   = 0.0095, comp  = 0.0052, lda = 2], class = talk: talk.politics.misc
doc 4: topic = [talk  = 0.0195, comp  = 0.0002, soc   = 0.0000, lda = 3], class = comp: comp.windows.x
doc 5: topic = [talk  = 0.0144, alt   = 0.0060, sci   = 0.0045, lda = 6], class = rec: rec.autos
doc 6: topic = [talk  = 0.0198, sci   = 0.0132, comp  = 0.0106, lda = 3], class = comp: comp.os.ms-windows.misc
doc 7: topic = [talk  = 0.0157, comp  = 0.0091, sci   = 0.0077, lda = 4], class = rec: rec.autos
doc 8: topic = [talk  = 0.0129, comp  = 0.0107, sci   = 0.0058, lda = 5], class = comp: comp.graphics
doc 9: topic = [talk  = 0.0241, sci   = 0.0138, comp  = 0.0129, lda = 4], class = comp: comp.graphics
doc 10: topic = [talk  = 0.0978, sci   = 0.0534, comp  = 0.0529, lda = 4], class = comp: comp.graphics
doc 11: topic = [talk  = 0.0132, sci   = 0.0104, comp  = 0.0098, lda = 6], class = comp: comp.graphics
doc 12: topic = [talk  = 0.0188, sci   = 0.0049, soc   = 0.0000, lda = 4], class = sci: sci.med
doc 13: topic = [talk  = 0.0143, sci   = 0.0082, comp  = 0.0072, lda = 6], class = soc: soc.religion.christian
doc 14: topic = [talk  = 0.0153, sci   = 0.0109, comp  = 0.0101, lda = 3], class = comp: comp.sys.ibm.pc.hardware
doc 15: topic = [talk  = 0.0186, comp  = 0.0120, sci   = 0.0106, lda = 4], class = sci: sci.space
doc 16: topic = [talk  = 0.0000, soc   = 0.0000, sci   = 0.0000, lda = 6], class = comp: comp.sys.mac.hardware
doc 17: topic = [talk  = 0.0141, comp  = 0.0095, alt   = 0.0086, lda = 6], class = rec: rec.sport.hockey
doc 18: topic = [talk  = 0.0129, sci   = 0.0078, comp  = 0.0072, lda = 6], class = soc: soc.religion.christian
doc 19: topic = [talk  = 0.0114, sci   = 0.0113, comp  = 0.0076, lda = 6], class = comp: comp.os.ms-windows.misc
doc 20: topic = [talk  = 0.0311, sci   = 0.0060, comp  = 0.0034, lda = 2], class = rec: rec.sport.hockey
doc 21: topic = [talk  = 0.0000, soc   = 0.0000, sci   = 0.0000, lda = 6], class = soc: soc.religion.christian
doc 22: topic = [talk  = 0.0102, sci   = 0.0075, comp  = 0.0060, lda = 2], class = comp: comp.windows.x
doc 23: topic = [talk  = 0.0217, sci   = 0.0114, comp  = 0.0097, lda = 4], class = sci: sci.med
doc 24: topic = [talk  = 0.0173, sci   = 0.0072, comp  = 0.0055, lda = 4], class = talk: talk.politics.misc
doc 25: topic = [talk  = 0.0231, sci   = 0.0111, comp  = 0.0093, lda = 4], class = soc: soc.religion.christian
doc 26: topic = [talk  = 0.0194, sci   = 0.0112, comp  = 0.0082, lda = 6], class = rec: rec.sport.baseball
doc 27: topic = [talk  = 0.0184, sci   = 0.0104, comp  = 0.0075, lda = 3], class = alt: alt.atheism
doc 28: topic = [talk  = 0.0109, sci   = 0.0107, comp  = 0.0061, lda = 6], class = sci: sci.med
doc 29: topic = [talk  = 0.0179, comp  = 0.0076, sci   = 0.0072, lda = 4], class = rec: rec.motorcycles
doc 30: topic = [talk  = 0.0190, sci   = 0.0068, comp  = 0.0062, lda = 6], class = talk: talk.religion.misc
doc 31: topic = [talk  = 0.0068, comp  = 0.0065, sci   = 0.0053, lda = 6], class = comp: comp.sys.ibm.pc.hardware
doc 32: topic = [comp  = 0.0120, talk  = 0.0100, sci   = 0.0081, lda = 5], class = comp: comp.graphics
doc 33: topic = [talk  = 0.0000, soc   = 0.0000, sci   = 0.0000, lda = 6], class = talk: talk.politics.misc
doc 34: topic = [talk  = 0.0154, comp  = 0.0071, alt   = 0.0055, lda = 3], class = talk: talk.politics.mideast
doc 35: topic = [talk  = 0.0180, comp  = 0.0087, sci   = 0.0074, lda = 6], class = talk: talk.politics.misc
doc 36: topic = [talk  = 0.0160, sci   = 0.0092, comp  = 0.0086, lda = 2], class = rec: rec.sport.baseball
doc 37: topic = [sci   = 0.0110, comp  = 0.0091, talk  = 0.0081, lda = 3], class = comp: comp.sys.mac.hardware
doc 38: topic = [talk  = 0.0182, comp  = 0.0101, sci   = 0.0095, lda = 4], class = comp: comp.sys.ibm.pc.hardware
doc 39: topic = [talk  = 0.0201, sci   = 0.0110, comp  = 0.0089, lda = 2], class = rec: rec.sport.baseball
doc 40: topic = [talk  = 0.0152, comp  = 0.0091, sci   = 0.0071, lda = 4], class = rec: rec.sport.baseball
doc 41: topic = [comp  = 0.0117, talk  = 0.0083, sci   = 0.0062, lda = 6], class = comp: comp.windows.x
doc 42: topic = [talk  = 0.0266, sci   = 0.0085, comp  = 0.0059, lda = 4], class = talk: talk.politics.mideast
doc 43: topic = [talk  = 0.0210, sci   = 0.0125, comp  = 0.0097, lda = 4], class = sci: sci.space
doc 44: topic = [talk  = 0.0131, sci   = 0.0075, comp  = 0.0051, lda = 3], class = talk: talk.politics.guns
doc 45: topic = [comp  = 0.0043, sci   = 0.0035, rec   = 0.0016, lda = 6], class = comp: comp.windows.x
doc 46: topic = [sci   = 0.0005, talk  = 0.0000, soc   = 0.0000, lda = 1], class = rec: rec.motorcycles
doc 47: topic = [talk  = 0.0157, comp  = 0.0098, sci   = 0.0077, lda = 5], class = comp: comp.sys.mac.hardware
doc 48: topic = [talk  = 0.0184, comp  = 0.0106, sci   = 0.0053, lda = 3], class = talk: talk.politics.guns
doc 49: topic = [talk  = 0.0188, sci   = 0.0094, comp  = 0.0070, lda = 4], class = talk: talk.politics.mideast

network_clusters = 7, lda_clusters = 7, topics = ['alt', 'comp', 'misc', 'rec', 'sci', 'soc', 'talk'], acc1 = 0.3, acc2 = 0.41

Purity
==============
lda = 0.4400, word_network = 0.8800

Entropy
==============
lda = 1.8691, word_network = 2.1629

Coherence
==============
  topic = 0: lda = 0.0000, word_network = 0.0000
  topic = 1: lda = 0.0000, word_network = 0.0000
  topic = 2: lda = 0.0000, word_network = 0.0000
  topic = 3: lda = 0.0000, word_network = 0.0000
  topic = 4: lda = 0.0000, word_network = 0.0000
  topic = 5: lda = 0.0000, word_network = 0.0000
  topic = 6: lda = 0.0000, word_network = 0.0000
lda = 0.0000, word_network = 0.0000

Perplexity
==============
lda = 744.1490, word_network = 4.4326
